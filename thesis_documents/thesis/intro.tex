\chapter{Introduction}

\section{Project Goals}

In this thesis, we present an end-to-end dialog simulation framework, called Socrates Sim, to support task completion dialog research. The goal of our framework is to provide a set of tools that simulate conversations between a user simulator and a dialog agent in order evaluate the performance of the dialog agent and generate annotated data. Specifically, the Socrates Sim allows researchers to define the custom dialog domains, build user simulators, and run multiple simulations with a provided dialog agent with a single unified framework. 

Task completion dialog agents have grown in popularity in the past few years. With the advent of home assistant services like Amazon's Alexa and advances in dialog research, there has been a rise in the development of dialog agents that provide various user services like flight bookings and restaurant recommendations. One of the key challenges in developing these agents is effectively training and evaluating them. There are only a handful of tools available to support dialog research. Missing in this space is a framework that facilitates end-to-end simulation between a user simulator and dialog agent. There are several value propositions for such a framework.

One of main challenges is that it is very expensive to train dialog agents and produce quality training data. It is a very labor intensive and human centric process. User simulators can alleviate the need for human testers by simulating human behavior. A framework that simulates the conversation between a user simulator and dialog agent can be used to generate large amounts of ancillary data to augment manually collected training data for model based dialog agents. Additionally, the framework provides standardized way to test the robustness and efficacy of a dialog agent.

The intended users of this framework are academic researchers and data scientists or software engineers in industry. The framework is modular and re-targetable to support multiple domains. Our framework makes it easy for the researcher to build and test different user simulators for their dialog agent and produce diverse datasets. 

In this thesis, our focus is on the design and implementation of the Socrates Sim framework. We use as inspiration the framework architecture described in \cite{li_usersim} and the configuration based approach used by \cite{Gardner_allennlp} for AllenNLP. The primary limitation of the \cite{li_end_to_end} framework is that it tightly couples the user simulator with the development of a dialog agent. As a result, adapting the framework to a new domain requires reimplementing the entire architecture. 

Our contribution is the design and implementation of a framework that generalizes to new domains in a scalable manner. We abstract and modularize key components in order to develop a framework that is domain independent. The researcher can plug in different dialog agents and user simulators in order to run simulations, evaluate the agent, and generate annotated training data. Additionally, we make the framework easier to use by utilizing a configuration based approach, in which the user specifies the simulation parameters in a external configuration file. The user can set up multiple experiments, change domains, dialog agents, and user simulators without having to write new code or manually provide it as a long list of command line parameters. Finally, our framework scales efficiently as the number of simulations it needs to generate increases. 

The framework consists of the following components:
\begin{itemize}
	\item \textbf{Dialog Domain}: A set of classes to represent the dialog domain and knowledge base. The dialog domain consists of all possible dialog acts, valid inform/request slots and values, and other domain specific information. 
	\item \textbf{Speaker Interface}: A unified interface that defines standardized protocol for the external user simulators and dialog agent to communicate with the framework. 
	\item \textbf{Dialog Manager}: A coordinator tool that facilitates the conversation between the user simulator and dialog agent. Additionally, the dialog manger tracks simulation histories, evaluates the simulated dialog, and serializes the annotated simulations to disk.  
\end{itemize}

In the next section, we provide more background on the evolution of task completion dialog research and the motivation for developing Socrates Sim. 

\section{Background}

Task completion dialog refers to the space of dialog activities, in which an end user engages with an interlocutor in order to complete a task or achieve a tangible goal. For example, imagine a user interacting with a concierge in order to identify and book a restaurant for dinner. In dialog systems, the human interlocutor is replaced by an artificial agent (also referred to as the system or dialog agent) that can intelligently respond and help the user achieve their goal.

Automated dialog systems are not a new concept. The have been used to support call routing (e.g. the press 1 to reach sales) in the context of customer support for banks, credit cards, flight booking, and many other commercial sectors since the 1970s. Central to any dialog system is the dialog policy. The dialog policy informs the system on what to say and what information to collect based on the state of conversation. Traditionally dialog policies were scripted out, usually following a simple flowchart like structure. This is known as a rules based approach, where rules are written out to capture system behavior under predefined situations/states. Rules based systems are limited, as they require the user to follow a scripted path and provide the system with one piece of information at time. While effective, many user are often frustrated with rule based dialog systems and tend to prefer speaking to a human agent. Much of this frustration is caused by the slow pacing of the dialog scripts, which require the user to specify information piecemeal in specific order. 

There has been significant progress in the AI and machine learning space that has led to the development of commercially viable intelligent dialog systems. In particular, the popularity of voice assistants like Amazon’s Alexa, Apple’s Siri, and Google's Assistant, have increased the demand for voice interfaces to popular applications and services. There has been a boom in the development of chat bots, third party voice skills for Alexa and Google Home, and other dialog based services. Much of this is due to the proliferation of exciting research which applies deep learning and machine learning to the dialog domain. 

However, developing good voice interfaces and dialog systems is still very challenging. For example, a significant percent of the voice skills in the Alexa skill store have poor ratings \cite{rey_2017}. According to research by recode.com, 69\% of skills in the Alexa skill store have a 0 or 1 reviews suggesting abysmal usage. In addition, there is only a 3\% chance that user will reuse a voice skill after first use, demonstrating poor retention. Underlying these poor statistics is the fundamental challenge - designing robust and usable dialog systems is very difficult. 
 
Rules based dialog systems are not scalable nor optimal for more complex task completion. Researchers have moved to leveraging supervised learning (SL) methods to train dialog systems and produce more robust dialog policies. In an SL approach, the dialog policy is trained to imitate the observed actions of an expert using annotated and manually crafted datasets based real human interactions \cite{Schatzmann2006ASO}. While this approach produces better policies than a rules based approach, it is limited to quality and scope of the training data. 

One of the key challenges in this space is developing quality and diverse training data. Producing deep annotated data is time consuming and expensive. The dataset may not comprehensively cover all possible states in a policy space. Supervised learning requires large amounts of clean and annotated training data. This involves having many human testers interacting with a human expert (which proxies for the dialog agent), in order to generate what the ideal conversations would look like. In response to user questions and actions, the human expert would choose the correct policy choice from a defined action space. Over the course of the dialog, the human expert identifies all the right actions that will eventually lead to helping the user accomplish their goal. This process is repeated across many users in order to capture the different goals a user may have and how they communicate. Current data gathering practices rely on crowd-sourcing and or general human trials. While these approaches are effective at generating hight quality data, they are incredibly expensive and limited in how information they can capture.  

Reinforcement learning (RL) methods are also gaining popularity. Given a reward function, the agent can optimize a dialog policy through interaction with users and learn what an optimal dialog policy should be. Reinforcement learning approaches are more robust than supervised learning techniques as the agent can explore more of the policy space.

A virtual simulator could alleviate these data needs, by simulating a user in place of using a real human user. The user simulator can be used in the context of supervised learning (SL) or reinforcement learning (RL) to train a dialog system on how to identify optimal policies. The simulator would help generate additional synthetic data to help augment the training data acquired through human testing. The user simulator also provides a useful starting point to train and RL based agents, which can be then further optimized in RL situation with real users \cite{li_usersim}. Currently, there is no open source or commercially available framework to support end-to-end simulations with user simulators. The aspiration of this thesis is to develop a solution that can fill that gap. 

\section{Prior Work}
\label{sec:priorworks}

The growing popularity of statistical approaches for spoken dialog systems has led to research for more optimal ways to generate training data. \cite{Schatzmann2009TheHA} introduced the concept of the hidden agenda user simulation model , which has been foundational to conceptualizing user simulators. Schatzmann and Young provide a formalized framework to capture user intents in stack-like structure of pending dialog acts. \cite{BordesW16} applied deep learning and neural models to dialog systems. They introduced the concept of a neural network-based end-to-end trainable dialog system. Their approach treats dialog system learning as problem learning and attempts to map dialog histories to systems responses by applying encoder-decoder models for training. 

\cite{li_usersim} developed a framework for a user simulator and released a research proof of concept which was applied to the movie booking domain. They released a proof-of-concept framework, TC-Bot. The framework was written in Python 2.7 and hard-coded to support the movie booking domain. Currently, there is no open source and modern user simulator tool for task-completion dialog research. Our framework is written it in Python 3.6.0 and applies good software engineering principles. It is our aspiration that Socrates Simulator can be used for other domains by the dialog research community. 

Finally, Facebook recently released the beta version ParlAI. ParlAI aims to provide a standardized and unified framework for developing dialog models. They’ve released a broad set of tools to support training and development of dialog systems for the following domain areas: question answering, goal oriented dialog, chit-chat dialog, visual qa/dialog and sentence completion. ParlAI offers a simplified set of API calls to common dialog datasets (e.g. SQuAD, bAbI tasks, MCTest, etc) and provides a set of hooks to Amazon’s Mechanical Turk to test one’s dialog model again real human testers. While, ParlAI offers an expansive set of tools and datasets, missing from its framework is support for incorporating user simulators. 

\section{Thesis Overview}

In this thesis we describe the architecture of Socrates Sim, provide implementation details for two different domains, and demonstrate our framework usability through a set of runtime performance evaluations. In chapter 2, we describe the architecture of the Socrates Sim framework. In particular, we focus on modeling conversations, how to standardize communication between external dialog agents and user simulators, and the underlying dialog management framework. 

In chapter 3, we describe the general implementation process for setting up and using Socrates Sim. In chapters 4 and 5, we specifically explore how Socrates Sim was adapted to support the restaurant and movie domains. We detail the development of user simulators, dialog agents, and the underlying dialog components for both domains. Additionally, we highlight the use of configuration files that allow for rapid experimentation and easy swapping of modular components without having to modify existing code. 

In chapter 6, we describe the development of Socrates Sim and cover the tools, language, and other programming specific choices made in developing Scorates Sim. In chapter 7, we provide evidence Socrates Sim is usable and efficient. Multiple performance tests were run to evaluate the runtime efficiency and memory consumption of Socrates Sim as it ran an increasing number of simulations. We used TC-Bot (\cite{li_end_to_end}) as a benchmark to evaluate performance. We show how Socrates Sim scales efficiently and is maintains a shallow linear growth for it runtime.

Finally, in chapter 8, we conclude this thesis. We describe known limitations, talk about the lessons learned, and provide suggestions for future work.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
