\chapter{Introduction}

Task completion dialog refers to the space of dialog activities, in which an end user engages with an interlocutor in order to complete a task or achieve a tangible goal. For example, imagine a user interacting with a concierge in order to identify and book a restaurant for dinner. In dialog systems, the human interlocutor is replaced by an artificial agent (also referred to as the system or dialog agent) that can intelligently respond and help the user achieve their goal.

Automated dialog systems are not a new concept. The have been used to support call routing (e.g. the press 1 to reach sales) in the context of customer support for banks, credit cards, flight booking, and many other commercial sectors since the 1970s. Central to any dialog system is the dialog policy. The dialog polciy informs the system on what to say and what information to collect based on the state of conversation. Traditionally dialog policies were scripted out, usually following a simple flowchart like structure. This is known as a rules based approach, where rules are written out to capture system behavior under predefined situations/states. Rules based systems are limited, as they require the user to follow a scripted path and provide the system with one piece of information at time. While effective, many user are often frustrated with rule based dialog systems and tend to prefer speaking to a human agent. Much of this frustration is caused by the slow pacing of the dialog scripts, which require the user to specify information piecemeal in specific order. 

There has been significant progress in the AI and machine learning space that has led to the development of commercially viable intelligent dialog systems. In particular, the popularity of voice assistants like Amazon’s Alexa, Apple’s Siri, and Google's Assistant, have increased the demand for voice interfaces to popular applications and services. There has been a boom in the development of chatbots, third party voice skills for Alexa and Google Home, and other dialog based services. Much of this is due to the proliferation of exciting research which applies deep learning and machine learning to the dialog domain. 

However, developing good voice interfaces and dialog systems is still very challenging. For example, a significant percent of the voice skills in the Alexa skill store have poor ratings \cite{rey_2017}. According to research by recode.com, 69\% of skills in the Alexa skill store have a 0 or 1 reviews suggesting abysmal usage. In addition, there only a 3\% chance that user will reuse a voice skill after first use, demonstrating poor retention. Underlying these poor statistics is the fundamental challenge - designing robust and usable dialog systems is very difficult. 
 
Rules based dialogs are not scalable or optimal for more complex task completion. Researchers have moved to leveraging supervised learning (SL) methods to train dialog systems and produce more robust dialog policies. In an SL approach, the dialog policy is trained to imitate observed actions of an expert using an annotated and manually crafted datasets based real human interactions \cite{Schatzmann2006ASO}. While this approach produces better policies than a rules based approach, it is limited to quality and scope of the training data. 

One of the key challenges in this space is developing quality and diverse training datasets. Producing deep annotated dataset is time consuming, expensive, and the dataset may not comprehensively cover all possible states in a policy space. Supervised learning requires large amounts of clean and annotated training data. This involves having many human testers interacting with a human expert (which proxies for the dialog agent), in order to generate what the ideal conversations would look like. In response to user questions and actions, the human expert would choose the correct policy choice from a defined action space. Over the course of the dialog, the human expert identifies all the right actions that will eventually lead to helping the user accomplish their goal. This process is repeated across many users in order to capture the different goals a user may have and how they communicate. Current data gathering practices rely on crowd-sourcing and or general human trials. While these approaches are effective at generating hight quality data, they are incredibly expensive and limited in how information they can capture.  

Reinforcement learning (RL) methods are also gaining popularity. Given a reward function, the agent can optimize a dialog policy through interaction with users and learn what an optimal dialog policy should be. Reinforcement learning approaches are more robust than supervised learning techniques as the agent can explore more of the policy space.

A virtual simulator could alleviate these data needs, by simulating a user in place of using a real human user. The user simulator can be used in the context of supervised learning (SL) or reinforcement learning (RL) to train a dialog system on how to identify optimal dialog policies. In this context, the simulator would generate additional synthetic data to help augment the training data acquired through human testing. The user simulator also provides a useful starting point to train and RL based agent, which can be then further optimized in RL situation with real users \cite{li_usersim}. Currently, there is no open source or commercially available user simulator framework to support dialog research. The aspiration of this thesis is to develop a solution that can fill that gap. 

\section{Prior Work}
\label{sec:priorworks}

The growing popularity of statistical approaches for spoken dialog systems has led to research for more optimal ways to generate training dialog data. Schatzmann and Young introduced the concept of the hidden agenda user simulation model [6], which has been foundational to conceptualizing user simulators. In their 2009 paper, Schatzmann and Young provided a formalized framework to capture user intents in stack-like structure of pending dialog acts. \cite{BordesW16} applied deep learning and neural models to dialog systems. They introduced a network-based end-to-end trainable dialog system, which treated dialog system learning as the problem learning to map dialog histories to systems responses and applying encoder-decoder models for training. 

\cite{li_usersim} developed a framework for a user simulator and released a research proof of concept which was applied to the movie booking domain. The released proof-of-concept, TC-Bot, was written in Python 2.7 and hard-coded to support the movie booking domain. Currently, there is no open source and modern user simulator tool for task-completion dialog research. This thesis aims to adapt their framework to the restaurant domain, write it in Python 3.7.0 and apply good software engineering principles with the aspiration that Socrates Simulator can be used for other domains by the dialog research community. 

Finally, Facebook recently released the beta version ParlAI. ParlAI aims to provide a standardized and unified framework for developing dialog models. They’ve released a broad set of tools to support training and development of dialog systems for the following domain areas: question answering, goal oriented dialog, chit-chat dialog, visual qa/dialog and sentence completion. ParlAI offers a simplified set of API calls to common dialog datasets (e.g. SQuAD, bAbI tasks, MCTest, etc) and provides a set of hooks to Amazon’s Mechanical Turk to test one’s dialog model again real human testers. While, ParlAI offer an expansive set of tools and datasets, missing from its framework is a user simulator. 

\section{Project Goals}

The goal of this thesis is develop a framework that will allow dialog researchers and to more easily develop user simulators and produce labeled training data for their dialog agents. The intended users of this framework would be academic researchers and data scientists or software engineers in industry. The framework will be modular and support multiple domains. Ideally, it should to be easy for the user to build and test different user simulators for their dialog agent and produce diverse dataset. 

Note, this thesis will not explore the efficacy of the data produced by user simulators. \cite{li_end_to_end}  and \cite{li_usersim} ran experiments in the movie booking domain and found promising results. [ADD finidings here ] Additional \cite{BordesW16} also found results for the restaurant booking domain. EXPAND THIS SECTION WITH SUMMARY FINDINGS.  

Our focus will be on the design and implementation of the Socrates Sim framework. As mentioned above, we will use as inspiration the framework architecture described in \cite{li_usersim} and the configuration based approach used by \cite{Gardner_allennlp} for AllenNLP. Significant work was done in designing a more general purpose and modular framework, in order to support a wider set of use cases. 
 The framework will consist of the following components:
\begin{itemize}
	\item \textbf{User Simulator}: An agenda based user modeling component that generates natural language speech utterances to simulate what an actual human would say in the context of task-completion dialog activity. 
	\item \textbf{Dialog Agent Interface}: A set of methods to allow a researcher to plug-in their dialog agent and have it interact with the user simulator
	\item \textbf{Dialog Manager}: A coordinator tool that will facilitate the conversation between the user simulator and dialog agent. The simulator will save the simulated conversations in a annotated format.
\end{itemize}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
