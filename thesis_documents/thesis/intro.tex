

\chapter{Introduction}
\label{chap:intro}

Task completion dialog refers to the space of dialog activities, in which a user engages with an interlocutor in an attempt to complete a task or achieve a tangible goal. For example, imagine a user interacting with a concierge in order to identify and book a restaurant for dinner. In dialog systems, the human interlocutor is replaced by an artificial agent (system/ dialog agent) that can intelligently respond and help the user achieve their goal
. 
One of the key challenges in this space is developing quality and diverse training datasets to support development of dialog agents, many of which rely on data intensive deep learning techniques. Current data gathering practices rely on using crowd-sourced and manual efforts, which are not sustainable and scalable.  The virtual simulator attempts to alleviate this need, by simulating a user and generating user utterances in place of a real human user. The user simulator can be used in the context of supervised learning (SL) or reinforcement learning (RL) to train a dialog system to identify optimal dialog policies. 
There has been significant progress in the dialog and AI space that led to the development of commercially viable intelligent voice systems. In particular, the popularity voices assistants like Amazon’s Alexa, Apple’s Siri, and Google assistant have increased the demand for voice interfaces to popular applications and services. There has been a boom in the development of chatbots, third party voice skills for Alexa and Google Home, and proliferation of exciting research applying deep learning and machine learning to the dialog domain. From a research point of view, the dialog domain is rich, complex, and challenging.
Automated dialog systems are not a new concept. The have been used to support call routing (e.g. the press 1 to reach sales) in the context of customer support for banks, credit cards, flight booking, and many other commercial sectors since the 1970s. Central to any dialog system is the dialog policy, which is responsible for informing the system on what to say and what information to collect based on the state of conversation. Traditionally dialog policies were scripted out, usually following a simple flowchart like structure. This is known as a rules based approach, where rules are written out to capture system behavior under predefined situations/states. Rules based systems are limited, as they required the user to follow a scripted paths and provide the system with one piece of information at time. With the advent of personal assistants like Siri and Alexa and chatbot, dialog system are evolving to support wider use cases and more open conversational dialog flows. 

However, developing good voice interfaces and systems is still very challenging. For example, a significant percent of the voice skills in the Alexa skill store have poor ratings \cite{rey_2017}. According to research by recode.com, 69% of skills in the Alexa skill store have zero or 1 reviews suggesting abysmal usage. In addition, there only a 3% chance that user will reuse a voice skill after first use, demonstrating poor retention. Underlying these poor statistics is the fundamental challenge - designing robust and usable dialog systems is very hard. 

Rules based dialogs are not scalable or optimal for more complex dialogs. Researchers have moved to leveraging supervised learning (SL) methods to train dialog systems and produce more robust dialog policies. In an SL approach, the dialog policy is trained to imitate observed actions of an expert using an annotated and manually crafted datasets based real human interactions \cite{Schatzmann2006ASO}. While this approach produces better policies than a rules based approach, it is limited to quality and scope of the training data. Producing deep annotated dataset is time consuming, expensive, and the dataset may not comprehensive cover all possible states in a policy space.

As result, reinforcement learning (RL) methods are gain popularity. Given a reward function, the agent can optimize a dialog policy through interaction with users and learn what an optimal dialog policy should be. As mentioned above, real interaction with users is time consuming and expensive. A user simulator that accurately simulates a real user can allow the RL agent to explore trajectories that may not have existed in observed data and produce larger datasets. The user simulator provides a useful starting point to train and RL based agent, which can be then further optimized in RL situation with real users \cite{li_usersim}. Currently, there is no general user simulator tool that researchers can use to develop dialog agents for various task completion domains. The aspiration of this thesis is to develop a solution that can fill that gap. 

\section{Prior Work}
\label{sec:priorworks}

The growing popularity of statistical approaches for spoken dialog systems has led to research for more optimal ways to generate training dialog data. Supervised learning methods and reinforcement learning methods offer great promise for development of robust goal-oriented task-completion dialog systems. Schatzmann and Young introduced the concept of the hidden agenda user simulation model [6], which has been foundational to conceptualizing user simulators. In their 2009 paper, Schatzmann and Young provided a formalized framework to capture user intents in stack-like structure of pending dialog acts. \cite{BordesW16} applied deep learning and neural models to dialog systems. They introduced a network-based end-to-end trainable dialog system, which treated dialog system learning as the problem learning to map dialog histories to systems responses and applying encoder-decoder models for training. 

\cite{li_usersim} developed a framework for a user simulator and released a research proof of concept which was applied to the movie booking domain. The released proof-of-concept, TC-Bot, was written in Python 2.7 and hard-coded to support the movie booking domain. Currently, there is no open source and modern user simulator tool for task-completion dialog research.  This thesis aims to adapt their framework to the restaurant domain, write it in Python 3.6.0 and apply good software engineering principles with the aspiration that Socrates Simulator can be used for other domains by the dialog research community. 

Finally, Facebook recently released the beta version ParlAI. ParlAI aims to provide a standardized and unified framework for developing dialog models. They’ve released a broad set of tools to support training and development of dialog systems for the following domain areas: question answering, goal oriented dialog, chit-chat dialog, visual qa/dialog and sentence completion. ParlAI offers a simplified set of API calls to common dialog datasets (e.g. SQuAD, bAbI tasks, MCTest, etc) and provides a set of hooks to Amazon’s Mechanical Turk to test one’s dialog model again real human testers. While, ParlAI offer an expansive set of tools and datasets, missing from its framework is a user simulator. 

\section{Project Goals}
\label{sec:goals}


...

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
